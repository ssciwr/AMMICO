

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>text module &mdash; AMMICO 0.2.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=000c92bf"></script>
      <script src="_static/doctools.js?v=9a2dae69"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="License" href="license_link.html" />
    <link rel="prev" title="AMMICO package modules" href="modules.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            AMMICO
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="readme_link.html">AMMICO - AI-based Media and Misinformation Content Analysis Tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq_link.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="create_API_key_link.html">Instructions how to generate and enable a google Cloud Vision API key</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/DemoNotebook_ammico.html">AMMICO Demonstration Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/DemoNotebook_ammico.html#Step-0:-Create-and-set-a-Google-Cloud-Vision-Key">Step 0: Create and set a Google Cloud Vision Key</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/DemoNotebook_ammico.html#Step-1:-Read-your-data-into-AMMICO">Step 1: Read your data into AMMICO</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/DemoNotebook_ammico.html#The-detector-modules">The detector modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/Example%20cropposts.html">Crop posts module</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">AMMICO package modules</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">text module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-summary">summary module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#summary.SummaryDetector"><code class="docutils literal notranslate"><span class="pre">SummaryDetector</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.all_allowed_model_types"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.all_allowed_model_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.allowed_analysis_types"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.allowed_analysis_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.allowed_model_types"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.allowed_model_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.allowed_new_model_types"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.allowed_new_model_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.analyse_image"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.analyse_image()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.analyse_questions"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.analyse_questions()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.analyse_summary"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.analyse_summary()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.check_model"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.check_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model_base"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model_base()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model_base_blip2_opt_caption_coco_opt67b"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model_base_blip2_opt_caption_coco_opt67b()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model_base_blip2_opt_pretrain_opt67b"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model_base_blip2_opt_pretrain_opt67b()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model_blip2_opt_caption_coco_opt27b"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model_blip2_opt_caption_coco_opt27b()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model_blip2_opt_pretrain_opt27b"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model_blip2_opt_pretrain_opt27b()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model_blip2_t5_caption_coco_flant5xl"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model_blip2_t5_caption_coco_flant5xl()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model_blip2_t5_pretrain_flant5xl"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model_blip2_t5_pretrain_flant5xl()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model_blip2_t5_pretrain_flant5xxl"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model_blip2_t5_pretrain_flant5xxl()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_model_large"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_model_large()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_new_model"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_new_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary.SummaryDetector.load_vqa_model"><code class="docutils literal notranslate"><span class="pre">SummaryDetector.load_vqa_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#multimodal-search-module">multimodal search module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-faces">faces module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#faces.EmotionDetector"><code class="docutils literal notranslate"><span class="pre">EmotionDetector</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#faces.EmotionDetector.analyse_image"><code class="docutils literal notranslate"><span class="pre">EmotionDetector.analyse_image()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#faces.EmotionDetector.analyze_single_face"><code class="docutils literal notranslate"><span class="pre">EmotionDetector.analyze_single_face()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#faces.EmotionDetector.clean_subdict"><code class="docutils literal notranslate"><span class="pre">EmotionDetector.clean_subdict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#faces.EmotionDetector.facial_expression_analysis"><code class="docutils literal notranslate"><span class="pre">EmotionDetector.facial_expression_analysis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#faces.EmotionDetector.set_keys"><code class="docutils literal notranslate"><span class="pre">EmotionDetector.set_keys()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#faces.EmotionDetector.wears_mask"><code class="docutils literal notranslate"><span class="pre">EmotionDetector.wears_mask()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#faces.deepface_symlink_processor"><code class="docutils literal notranslate"><span class="pre">deepface_symlink_processor()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#faces.ethical_disclosure"><code class="docutils literal notranslate"><span class="pre">ethical_disclosure()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-colors">color_analysis module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#colors.ColorDetector"><code class="docutils literal notranslate"><span class="pre">ColorDetector</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#colors.ColorDetector.analyse_image"><code class="docutils literal notranslate"><span class="pre">ColorDetector.analyse_image()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#colors.ColorDetector.rgb2name"><code class="docutils literal notranslate"><span class="pre">ColorDetector.rgb2name()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#colors.ColorDetector.set_keys"><code class="docutils literal notranslate"><span class="pre">ColorDetector.set_keys()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-cropposts">cropposts module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cropposts.compute_crop_corner"><code class="docutils literal notranslate"><span class="pre">compute_crop_corner()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cropposts.crop_image_from_post"><code class="docutils literal notranslate"><span class="pre">crop_image_from_post()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cropposts.crop_media_posts"><code class="docutils literal notranslate"><span class="pre">crop_media_posts()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cropposts.crop_posts_from_refs"><code class="docutils literal notranslate"><span class="pre">crop_posts_from_refs()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cropposts.crop_posts_image"><code class="docutils literal notranslate"><span class="pre">crop_posts_image()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cropposts.draw_matches"><code class="docutils literal notranslate"><span class="pre">draw_matches()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cropposts.kp_from_matches"><code class="docutils literal notranslate"><span class="pre">kp_from_matches()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cropposts.matching_points"><code class="docutils literal notranslate"><span class="pre">matching_points()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cropposts.paste_image_and_comment"><code class="docutils literal notranslate"><span class="pre">paste_image_and_comment()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#utils-module">utils module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#display-module">display module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="license_link.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AMMICO</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">AMMICO package modules</a></li>
      <li class="breadcrumb-item active">text module</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ssciwr/AMMICO/blob/main/docs/source/ammico.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="text-module">
<h1>text module<a class="headerlink" href="#text-module" title="Link to this heading"></a></h1>
</section>
<section id="module-summary">
<span id="summary-module"></span><h1>summary module<a class="headerlink" href="#module-summary" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="summary.SummaryDetector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">summary.</span></span><span class="sig-name descname"><span class="pre">SummaryDetector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subdict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'base'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">analysis_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'summary_and_questions'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_of_questions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_vis_processors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_vqa_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_vqa_vis_processors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_vqa_txt_processors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_vqa_model_new</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_vqa_vis_processors_new</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_vqa_txt_processors_new</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AnalysisMethod</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="summary.SummaryDetector.all_allowed_model_types">
<span class="sig-name descname"><span class="pre">all_allowed_model_types</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['base',</span> <span class="pre">'large',</span> <span class="pre">'vqa',</span> <span class="pre">'blip2_t5_pretrain_flant5xxl',</span> <span class="pre">'blip2_t5_pretrain_flant5xl',</span> <span class="pre">'blip2_t5_caption_coco_flant5xl',</span> <span class="pre">'blip2_opt_pretrain_opt2.7b',</span> <span class="pre">'blip2_opt_pretrain_opt6.7b',</span> <span class="pre">'blip2_opt_caption_coco_opt2.7b',</span> <span class="pre">'blip2_opt_caption_coco_opt6.7b']</span></em><a class="headerlink" href="#summary.SummaryDetector.all_allowed_model_types" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="summary.SummaryDetector.allowed_analysis_types">
<span class="sig-name descname"><span class="pre">allowed_analysis_types</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['summary',</span> <span class="pre">'questions',</span> <span class="pre">'summary_and_questions']</span></em><a class="headerlink" href="#summary.SummaryDetector.allowed_analysis_types" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="summary.SummaryDetector.allowed_model_types">
<span class="sig-name descname"><span class="pre">allowed_model_types</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['base',</span> <span class="pre">'large',</span> <span class="pre">'vqa']</span></em><a class="headerlink" href="#summary.SummaryDetector.allowed_model_types" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="summary.SummaryDetector.allowed_new_model_types">
<span class="sig-name descname"><span class="pre">allowed_new_model_types</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['blip2_t5_pretrain_flant5xxl',</span> <span class="pre">'blip2_t5_pretrain_flant5xl',</span> <span class="pre">'blip2_t5_caption_coco_flant5xl',</span> <span class="pre">'blip2_opt_pretrain_opt2.7b',</span> <span class="pre">'blip2_opt_pretrain_opt6.7b',</span> <span class="pre">'blip2_opt_caption_coco_opt2.7b',</span> <span class="pre">'blip2_opt_caption_coco_opt6.7b']</span></em><a class="headerlink" href="#summary.SummaryDetector.allowed_new_model_types" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.analyse_image">
<span class="sig-name descname"><span class="pre">analyse_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subdict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">analysis_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_of_questions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">consequential_questions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.analyse_image" title="Link to this definition"></a></dt>
<dd><p>Analyse image with blip_caption model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>analysis_type</strong> (<em>str</em>) – type of the analysis.</p></li>
<li><p><strong>subdict</strong> (<em>dict</em>) – dictionary with analising pictures.</p></li>
<li><p><strong>list_of_questions</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – list of questions.</p></li>
<li><p><strong>consequential_questions</strong> (<em>bool</em>) – whether to ask consequential questions. Works only for new BLIP2 models.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self.subdict</strong> (<em>dict</em>) – dictionary with analysis results.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.analyse_questions">
<span class="sig-name descname"><span class="pre">analyse_questions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_of_questions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">consequential_questions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#summary.SummaryDetector.analyse_questions" title="Link to this definition"></a></dt>
<dd><p>Generate answers to free-form questions about image written in natural language.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>list_of_questions</strong> (<em>list</em><em>[</em><em>str</em><em>]</em>) – list of questions.</p></li>
<li><p><strong>consequential_questions</strong> (<em>bool</em>) – whether to ask consequential questions. Works only for new BLIP2 models.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self.subdict</strong> (<em>dict</em>) – dictionary with answers to questions.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.analyse_summary">
<span class="sig-name descname"><span class="pre">analyse_summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nondeterministic_summaries</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.analyse_summary" title="Link to this definition"></a></dt>
<dd><p>Create 1 constant and 3 non deterministic captions for image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>nondeterministic_summaries</strong> (<em>bool</em>) – whether to create 3 non deterministic captions.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self.subdict</strong> (<em>dict</em>) – dictionary with analysis results.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.check_model">
<span class="sig-name descname"><span class="pre">check_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.check_model" title="Link to this definition"></a></dt>
<dd><p>Check model type and return appropriate model and preprocessors.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>nn.Module</em>) – model.</p></li>
<li><p><strong>vis_processors</strong> (<em>dict</em>) – visual preprocessor.</p></li>
<li><p><strong>txt_processors</strong> (<em>dict</em>) – text preprocessor.</p></li>
<li><p><strong>model_old</strong> (<em>bool</em>) – whether model is old or new.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model" title="Link to this definition"></a></dt>
<dd><p>Load blip_caption model and preprocessors for visual inputs from lavis.models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_type</strong> (<em>str</em>) – type of the model.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>summary_model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>summary_vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model_base">
<span class="sig-name descname"><span class="pre">load_model_base</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model_base" title="Link to this definition"></a></dt>
<dd><p>Load base_coco blip_caption model and preprocessors for visual inputs from lavis.models.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>summary_model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>summary_vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model_base_blip2_opt_caption_coco_opt67b">
<span class="sig-name descname"><span class="pre">load_model_base_blip2_opt_caption_coco_opt67b</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model_base_blip2_opt_caption_coco_opt67b" title="Link to this definition"></a></dt>
<dd><p>Load BLIP2 model with caption_coco_opt6.7b architecture.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
<li><p><strong>txt_processors</strong> (<em>dict</em>) – preprocessors for text inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model_base_blip2_opt_pretrain_opt67b">
<span class="sig-name descname"><span class="pre">load_model_base_blip2_opt_pretrain_opt67b</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model_base_blip2_opt_pretrain_opt67b" title="Link to this definition"></a></dt>
<dd><p>Load BLIP2 model with pretrain_opt6.7b architecture.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
<li><p><strong>txt_processors</strong> (<em>dict</em>) – preprocessors for text inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model_blip2_opt_caption_coco_opt27b">
<span class="sig-name descname"><span class="pre">load_model_blip2_opt_caption_coco_opt27b</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model_blip2_opt_caption_coco_opt27b" title="Link to this definition"></a></dt>
<dd><p>Load BLIP2 model with caption_coco_opt2.7b architecture.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
<li><p><strong>txt_processors</strong> (<em>dict</em>) – preprocessors for text inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model_blip2_opt_pretrain_opt27b">
<span class="sig-name descname"><span class="pre">load_model_blip2_opt_pretrain_opt27b</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model_blip2_opt_pretrain_opt27b" title="Link to this definition"></a></dt>
<dd><p>Load BLIP2 model with pretrain_opt2 architecture.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
<li><p><strong>txt_processors</strong> (<em>dict</em>) – preprocessors for text inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model_blip2_t5_caption_coco_flant5xl">
<span class="sig-name descname"><span class="pre">load_model_blip2_t5_caption_coco_flant5xl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model_blip2_t5_caption_coco_flant5xl" title="Link to this definition"></a></dt>
<dd><p>Load BLIP2 model with caption_coco_flant5xl architecture.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
<li><p><strong>txt_processors</strong> (<em>dict</em>) – preprocessors for text inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model_blip2_t5_pretrain_flant5xl">
<span class="sig-name descname"><span class="pre">load_model_blip2_t5_pretrain_flant5xl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model_blip2_t5_pretrain_flant5xl" title="Link to this definition"></a></dt>
<dd><p>Load BLIP2 model with FLAN-T5 XL architecture.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
<li><p><strong>txt_processors</strong> (<em>dict</em>) – preprocessors for text inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model_blip2_t5_pretrain_flant5xxl">
<span class="sig-name descname"><span class="pre">load_model_blip2_t5_pretrain_flant5xxl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model_blip2_t5_pretrain_flant5xxl" title="Link to this definition"></a></dt>
<dd><p>Load BLIP2 model with FLAN-T5 XXL architecture.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
<li><p><strong>txt_processors</strong> (<em>dict</em>) – preprocessors for text inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_model_large">
<span class="sig-name descname"><span class="pre">load_model_large</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_model_large" title="Link to this definition"></a></dt>
<dd><p>Load large_coco blip_caption model and preprocessors for visual inputs from lavis.models.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>summary_model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>summary_vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_new_model">
<span class="sig-name descname"><span class="pre">load_new_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_new_model" title="Link to this definition"></a></dt>
<dd><p>Load new BLIP2 models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_type</strong> (<em>str</em>) – type of the model.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
<li><p><strong>txt_processors</strong> (<em>dict</em>) – preprocessors for text inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="summary.SummaryDetector.load_vqa_model">
<span class="sig-name descname"><span class="pre">load_vqa_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#summary.SummaryDetector.load_vqa_model" title="Link to this definition"></a></dt>
<dd><p>Load blip_vqa model and preprocessors for visual and text inputs from lavis.models.</p>
<p>Args:</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>summary_vqa_model</strong> (<em>torch.nn.Module</em>) – model.</p></li>
<li><p><strong>summary_vqa_vis_processors</strong> (<em>dict</em>) – preprocessors for visual inputs.</p></li>
<li><p><strong>summary_vqa_txt_processors</strong> (<em>dict</em>) – preprocessors for text inputs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="multimodal-search-module">
<h1>multimodal search module<a class="headerlink" href="#multimodal-search-module" title="Link to this heading"></a></h1>
</section>
<section id="module-faces">
<span id="faces-module"></span><h1>faces module<a class="headerlink" href="#module-faces" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="faces.EmotionDetector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">faces.</span></span><span class="sig-name descname"><span class="pre">EmotionDetector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subdict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emotion_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">race_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gender_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accept_disclosure</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'DISCLOSURE_AMMICO'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#faces.EmotionDetector" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AnalysisMethod</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="faces.EmotionDetector.analyse_image">
<span class="sig-name descname"><span class="pre">analyse_image</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#faces.EmotionDetector.analyse_image" title="Link to this definition"></a></dt>
<dd><p>Performs facial expression analysis on the image.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dict</strong> – The updated subdict dictionary with analysis results.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="faces.EmotionDetector.analyze_single_face">
<span class="sig-name descname"><span class="pre">analyze_single_face</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">face</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#faces.EmotionDetector.analyze_single_face" title="Link to this definition"></a></dt>
<dd><p>Analyzes the features of a single face on the image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>face</strong> (<em>np.ndarray</em>) – The face image array.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>dict</strong> – The analysis results for the face.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="faces.EmotionDetector.clean_subdict">
<span class="sig-name descname"><span class="pre">clean_subdict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#faces.EmotionDetector.clean_subdict" title="Link to this definition"></a></dt>
<dd><p>Cleans the subdict dictionary by converting results into appropriate formats.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>result</strong> (<em>dict</em>) – The analysis results.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>dict</strong> – The updated subdict dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="faces.EmotionDetector.facial_expression_analysis">
<span class="sig-name descname"><span class="pre">facial_expression_analysis</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#faces.EmotionDetector.facial_expression_analysis" title="Link to this definition"></a></dt>
<dd><p>Performs facial expression analysis on the image.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dict</strong> – The updated subdict dictionary with analysis results.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="faces.EmotionDetector.set_keys">
<span class="sig-name descname"><span class="pre">set_keys</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#faces.EmotionDetector.set_keys" title="Link to this definition"></a></dt>
<dd><p>Sets the initial parameters for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dict</strong> – The dictionary with initial parameter values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="faces.EmotionDetector.wears_mask">
<span class="sig-name descname"><span class="pre">wears_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">face</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#faces.EmotionDetector.wears_mask" title="Link to this definition"></a></dt>
<dd><p>Determines whether a face wears a mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>face</strong> (<em>np.ndarray</em>) – The face image array.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>bool</strong> – True if the face wears a mask, False otherwise.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="faces.deepface_symlink_processor">
<span class="sig-prename descclassname"><span class="pre">faces.</span></span><span class="sig-name descname"><span class="pre">deepface_symlink_processor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#faces.deepface_symlink_processor" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="faces.ethical_disclosure">
<span class="sig-prename descclassname"><span class="pre">faces.</span></span><span class="sig-name descname"><span class="pre">ethical_disclosure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">accept_disclosure</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'DISCLOSURE_AMMICO'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#faces.ethical_disclosure" title="Link to this definition"></a></dt>
<dd><p>Asks the user to accept the ethical disclosure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>accept_disclosure</strong> (<em>str</em>) – The name of the disclosure variable (default: “DISCLOSURE_AMMICO”).</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-colors">
<span id="color-analysis-module"></span><h1>color_analysis module<a class="headerlink" href="#module-colors" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="colors.ColorDetector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">colors.</span></span><span class="sig-name descname"><span class="pre">ColorDetector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subdict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delta_e_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'CIE</span> <span class="pre">1976'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#colors.ColorDetector" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AnalysisMethod</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="colors.ColorDetector.analyse_image">
<span class="sig-name descname"><span class="pre">analyse_image</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#colors.ColorDetector.analyse_image" title="Link to this definition"></a></dt>
<dd><p>Uses the colorgram library to extract the n most common colors from the images.
One problem is, that the most common colors are taken before beeing categorized,
so for small values it might occur that the ten most common colors are shades of grey,
while other colors are present but will be ignored. Because of this n_colors=100 was chosen as default.</p>
<p>The colors are then matched to the closest color in the CSS3 color list using the delta-e metric.
They are then merged into one data frame.
The colors can be reduced to a smaller list of colors using the get_color_table function.
These colors are: “red”, “green”, “blue”, “yellow”,”cyan”, “orange”, “purple”, “pink”, “brown”, “grey”, “white”, “black”.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dict</strong> – Dictionary with color names as keys and percentage of color in image as values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="colors.ColorDetector.rgb2name">
<span class="sig-name descname"><span class="pre">rgb2name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">c</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">merge_color</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delta_e_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'CIE</span> <span class="pre">1976'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#colors.ColorDetector.rgb2name" title="Link to this definition"></a></dt>
<dd><p>Take an rgb color as input and return the closest color name from the CSS3 color list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>c</strong> (<em>Union</em><em>[</em><em>List</em><em>,</em><em>tuple</em><em>]</em>) – RGB value.</p></li>
<li><p><strong>merge_color</strong> (<em>bool</em><em>, </em><em>Optional</em>) – Whether color name should be reduced, defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>str</strong> – Closest matching color name.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="colors.ColorDetector.set_keys">
<span class="sig-name descname"><span class="pre">set_keys</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#colors.ColorDetector.set_keys" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-cropposts">
<span id="cropposts-module"></span><h1>cropposts module<a class="headerlink" href="#module-cropposts" title="Link to this heading"></a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="cropposts.compute_crop_corner">
<span class="sig-prename descclassname"><span class="pre">cropposts.</span></span><span class="sig-name descname"><span class="pre">compute_crop_corner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">matches</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DMatch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kp1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kp2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">region</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_margin</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_margin</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_match</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">6</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="headerlink" href="#cropposts.compute_crop_corner" title="Link to this definition"></a></dt>
<dd><p>Estimate the position on the image from where to crop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>matches</strong> (<em>cv2.DMatch</em>) – The matched objects on the image.</p></li>
<li><p><strong>kp1</strong> (<em>np.ndarray</em>) – Key points of the matches for the reference image.</p></li>
<li><p><strong>kp2</strong> (<em>np.ndarray</em>) – Key points of the matches for the social media posts.</p></li>
<li><p><strong>region</strong> (<em>int</em><em>, </em><em>optional</em>) – Area to consider around the keypoints.
Defaults to 30.</p></li>
<li><p><strong>h_margin</strong> (<em>int</em><em>, </em><em>optional</em>) – Horizontal margin to subtract from the minimum
horizontal position. Defaults to 0.</p></li>
<li><p><strong>v_margin</strong> (<em>int</em><em>, </em><em>optional</em>) – Vertical margin to subtract from the minimum
vertical position. Defaults to 5.</p></li>
<li><p><strong>min_match</strong> – Minimum number of matches required. Defaults to 6.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>tuple, optional</strong> – Tuple of vertical and horizontal crop corner coordinates.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cropposts.crop_image_from_post">
<span class="sig-prename descclassname"><span class="pre">cropposts.</span></span><span class="sig-name descname"><span class="pre">crop_image_from_post</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">view</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_h</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#cropposts.crop_image_from_post" title="Link to this definition"></a></dt>
<dd><p>Crop the image part from the social media post.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>view</strong> (<em>np.ndarray</em>) – The image to be cropped.</p></li>
<li><p><strong>final_h</strong> – The horizontal position up to which should be cropped.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>np.ndarray</strong> – The cropped image part.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cropposts.crop_media_posts">
<span class="sig-prename descclassname"><span class="pre">cropposts.</span></span><span class="sig-name descname"><span class="pre">crop_media_posts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">files</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_files</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_crop_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plt_match</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plt_crop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plt_image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#cropposts.crop_media_posts" title="Link to this definition"></a></dt>
<dd><p>Crop social media posts so that comments beyond the first comment/post are cut off.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>files</strong> (<em>list</em>) – List of all the files to be cropped.</p></li>
<li><p><strong>ref_files</strong> (<em>list</em>) – List of all the reference images that signify
below which regions should be cropped.</p></li>
<li><p><strong>save_crop_dir</strong> (<em>str</em>) – Directory where to write the cropped social media posts to.</p></li>
<li><p><strong>plt_match</strong> (<em>Bool</em><em>, </em><em>optional</em>) – Display the matched areas on the social media post.
Defaults to False.</p></li>
<li><p><strong>plt_crop</strong> (<em>Bool</em><em>, </em><em>optional</em>) – Display the cropped text part of the social media post.
Defaults to False.</p></li>
<li><p><strong>plt_image</strong> (<em>Bool</em><em>, </em><em>optional</em>) – Display the image part of the social media post.
Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cropposts.crop_posts_from_refs">
<span class="sig-prename descclassname"><span class="pre">cropposts.</span></span><span class="sig-name descname"><span class="pre">crop_posts_from_refs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ref_views</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">view</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plt_match</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plt_crop</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plt_image</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#cropposts.crop_posts_from_refs" title="Link to this definition"></a></dt>
<dd><p>Crop the social media post comments from the image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ref_views</strong> (<em>list</em>) – List of all the reference images (as numpy arrays) that signify
below which regions should be cropped.</p></li>
<li><p><strong>view</strong> (<em>np.ndarray</em>) – The image to crop.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>np.ndarray</strong> – The cropped social media post.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cropposts.crop_posts_image">
<span class="sig-prename descclassname"><span class="pre">cropposts.</span></span><span class="sig-name descname"><span class="pre">crop_posts_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ref_view</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">view</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#cropposts.crop_posts_image" title="Link to this definition"></a></dt>
<dd><p>Crop the social media post to exclude additional comments. Sometimes also crops the
image part of the post - this is put back in later.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ref_views</strong> (<em>list</em>) – List of all the reference images (as numpy arrays) that signify
below which regions should be cropped.</p></li>
<li><p><strong>view</strong> (<em>np.ndarray</em>) – The image to crop.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>np.ndarray</strong> – The cropped social media post.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cropposts.draw_matches">
<span class="sig-prename descclassname"><span class="pre">cropposts.</span></span><span class="sig-name descname"><span class="pre">draw_matches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">matches</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kp1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">KeyPoint</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kp2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">KeyPoint</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#cropposts.draw_matches" title="Link to this definition"></a></dt>
<dd><p>Visualize the matches from SIFT.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>matches</strong> (<em>list</em><em>[</em><em>cv2.Match</em><em>]</em>) – List of cv2.Match matches on the image.</p></li>
<li><p><strong>img1</strong> (<em>np.ndarray</em>) – The reference image.</p></li>
<li><p><strong>img2</strong> (<em>np.ndarray</em>) – The social media post.</p></li>
<li><p><strong>kp1</strong> (<em>list</em><em>[</em><em>cv2.KeyPoint</em><em>]</em>) – List of keypoints from the first image.</p></li>
<li><p><strong>kp2</strong> (<em>list</em><em>[</em><em>cv2.KeyPoint</em><em>]</em>) – List of keypoints from the second image.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cropposts.kp_from_matches">
<span class="sig-prename descclassname"><span class="pre">cropposts.</span></span><span class="sig-name descname"><span class="pre">kp_from_matches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">matches</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kp1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kp2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#cropposts.kp_from_matches" title="Link to this definition"></a></dt>
<dd><p>Extract the match indices from the keypoints.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kp1</strong> (<em>np.ndarray</em>) – Key points of the matches,</p></li>
<li><p><strong>kp2</strong> (<em>np.ndarray</em>) – Key points of the matches,</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>tuple</strong> – Index of the descriptor in the list of train descriptors.</p></li>
<li><p><strong>tuple</strong> – index of the descriptor in the list of query descriptors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cropposts.matching_points">
<span class="sig-prename descclassname"><span class="pre">cropposts.</span></span><span class="sig-name descname"><span class="pre">matching_points</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">DMatch</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">KeyPoint</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">KeyPoint</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#cropposts.matching_points" title="Link to this definition"></a></dt>
<dd><p>Computes keypoint matches using the SIFT algorithm between two images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img1</strong> (<em>np.ndarray</em>) – The reference image.</p></li>
<li><p><strong>img2</strong> (<em>np.ndarray</em>) – The social media post.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>cv2.DMatch</strong> – List of filtered keypoint matches.</p></li>
<li><p><strong>cv2.KeyPoint</strong> – List of keypoints from the first image.</p></li>
<li><p><strong>cv2.KeyPoint</strong> – List of keypoints from the second image.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cropposts.paste_image_and_comment">
<span class="sig-prename descclassname"><span class="pre">cropposts.</span></span><span class="sig-name descname"><span class="pre">paste_image_and_comment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">crop_post</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_view</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="headerlink" href="#cropposts.paste_image_and_comment" title="Link to this definition"></a></dt>
<dd><p>Paste the image part and the text part together without the unecessary comments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>crop_post</strong> (<em>np.ndarray</em>) – The cropped image part of the social media post.</p></li>
<li><p><strong>crop_view</strong> (<em>np.ndarray</em>) – The cropped text part of the social media post.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>np.ndarray</strong> – The image and text part of the social media post in one image.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="utils-module">
<h1>utils module<a class="headerlink" href="#utils-module" title="Link to this heading"></a></h1>
</section>
<section id="display-module">
<h1>display module<a class="headerlink" href="#display-module" title="Link to this heading"></a></h1>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modules.html" class="btn btn-neutral float-left" title="AMMICO package modules" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="license_link.html" class="btn btn-neutral float-right" title="License" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Scientific Software Center, Heidelberg University.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>