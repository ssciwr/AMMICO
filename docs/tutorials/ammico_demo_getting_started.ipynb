{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Getting started with `ammico`\n",
    "\n",
    "With `ammico`, you can analyze text on images and image content at the same time. This is a tutorial notebook to get you started.\n",
    "You can run this notebook on google colab or locally / on your own HPC resource. For production data processing, it is recommended to run the analysis locally on a GPU-supported machine. You can also make use of the colab GPU runtime, or purchase additional runtime. However, google colab comes with pre-installed libraries that can lead to dependency conflicts. \n",
    "\n",
    "This first cell only runs on google colab; on all other machines, you need to create a conda environment first and install ammico from the Python Package Index using  \n",
    "```pip install ammico```  \n",
    "Alternatively you can install the development version from the GitHub repository  \n",
    "```pip install git+https://github.com/ssciwr/AMMICO.git```\n",
    "\n",
    "On google colab, select \"TPU\" as runtime, otherwise the notebook may not run:  \n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "  <img src=\"../_static/select_runtime.png\" alt=\"Select Runtime\" style=\"width: 45%;\">\n",
    "  <img src=\"../_static/runtime_options.png\" alt=\"Runtime Options\" style=\"width: 45%;\">\n",
    "</div>\n",
    "\n",
    "Then you need to uninstall the already installed `transformers` version, and `peft`, since these lead to dependency conflicts. Then you can install `ammico`. Simply execute the cell below by pressing shift+enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when running on Google colab, otherwise the below cell is skipped\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # uv is a fast Python package manager, see https://github.com/astral-sh/uv\n",
    "    %pip install uv\n",
    "    # Uninstall conflicting packages\n",
    "    !uv pip uninstall peft transformers\n",
    "    # Install ammico as the latest version from GitHub, which will pull in the compatible dependencies\n",
    "    !uv pip install git+https://github.com/ssciwr/ammico.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Now you need to restart the kernel to load the new dependencies. For this, click on \"Runtime -> Restart Session\" or press Ctrl+M.\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "  <img src=\"../_static/restart_session.png\" alt=\"Restart Session\" style=\"width: 45%;\">\n",
    "</div>\n",
    "\n",
    "Now you are ready to import ammico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ammico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "This imports all the functionality from `ammico`. To analyze images, you need to upload images to google colab or [connect to your Google Drive](https://colab.research.google.com/notebooks/io.ipynb). To upload files (note that these will not persist over the runtime of the notebook), click on the folder symbol (\"Files\") on the left navbar and press the upload button.\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "  <img src=\"../_static/select_files.png\" alt=\"Select Files\" style=\"width: 45%;\">\n",
    "  <img src=\"../_static/upload_files.png\" alt=\"Upload Files\" style=\"width: 45%;\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Step 1: Read your data into AMMICO\n",
    "\n",
    "`ammico` reads in files from a directory. You can iterate through directories in a recursive manner and filter by extensions. Note that the order of the files may vary on different OS. Reading in these files creates a dictionary `image_dict`, with one entry per image file, containing the file path and filename. This dictionary is the main data structure that ammico operates on and is extended successively with each detector run as explained below.\n",
    "\n",
    "For reading in the files, the ammico function `find_files` is used, with optional keywords:\n",
    "\n",
    "| input key | input type | possible input values |\n",
    "| --------- | ---------- | --------------------- |\n",
    "`path` | `str` | the directory containing the image files (defaults to the location set by environment variable `AMMICO_DATA_HOME`) |\n",
    "| `pattern` | `str\\|list` | the file extensions to consider (defaults to \"png\", \"jpg\", \"jpeg\", \"gif\", \"webp\", \"avif\", \"tiff\") |\n",
    "| `recursive` | `bool` | include subdirectories recursively (defaults to `True`) |\n",
    "| `limit` | `int` | maximum number of files to read (defaults to `20`, for all images set to `None` or `-1`) |\n",
    "| `random_seed` | `int` | the random seed for shuffling the images; applies when only a few images are read and the selection should be preserved (defaults to `None`) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data path\n",
    "data_path = \".\"  # the current directory\n",
    "\n",
    "# Find files and create the image dictionary\n",
    "image_dict = ammico.find_files(\n",
    "    path=data_path,\n",
    "    limit=10,  # Limit the number of files to process (optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# 2. Run the content analysis: Image summary\n",
    "\n",
    "As an example we will create an image caption (\"Summary\") using the [QWEN 2.5 Vision-Language model family](https://huggingface.co/collections/Qwen/qwen25-vl). Two variants are supported:\n",
    "\n",
    "This module is built on the Qwen2.5-VL model family. In this project, two model variants are supported: \n",
    "\n",
    "1. `Qwen2.5-VL-3B-Instruct`, which requires approximately 3 GB of video memory to load.\n",
    "2. `Qwen2.5-VL-7B-Instruct`, which requires 8.5 GB of VRAM for initialization (default).\n",
    "\n",
    "First, the model needs to be specified and loaded into memory. This will take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ammico.MultimodalSummaryModel()  # load the default model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Then, we create an instance of the Python class that handles the image summary and visual question answering tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_summary_vqa = ammico.ImageSummaryDetector(summary_model=model, subdict=image_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "After this, we can create the image captions. Depending on the number of images and the hardware provided, this can take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = image_summary_vqa.analyse_images_from_dict(\n",
    "    analysis_type=\"summary\", is_concise_summary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "The results are provided in the updated dictionary. Execute the cell below to see the image that was analyzed together with the generated caption (summary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key in summary.keys():\n",
    "    # Load and display the image\n",
    "    image_path = summary[key][\"filename\"]\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")  # Hide axes\n",
    "    plt.title(f\"Summary: {summary[key]['caption']}\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# 3. Run the content analysis: Visual question answering\n",
    "\n",
    "You may also ask questions about the images. For this, provide a list of questions and pass it to the Python class that you have instantiated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_questions = [\n",
    "    \"Who is in the picture?\",\n",
    "    \"Is Trump in the picture, answer with only yes or no?\",\n",
    "]  # add or replace with your own questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_and_answers = image_summary_vqa.analyse_images_from_dict(\n",
    "    analysis_type=\"summary_and_questions\",\n",
    "    list_of_questions=list_of_questions,\n",
    "    is_concise_summary=True,\n",
    "    is_concise_answer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Again for your convenience we display the images and the answers to the questions together below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for key in summary_and_answers.keys():\n",
    "    # Load and display the image\n",
    "    image_path = summary_and_answers[key][\"filename\"]\n",
    "    img = Image.open(image_path)\n",
    "    for answer in summary_and_answers[key][\"vqa\"]:\n",
    "        pprint(answer, width=100, compact=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")  # Hide axes\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# 4. Export the results\n",
    "\n",
    "To export the results for further processing, convert the image dictionary into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = ammico.get_dataframe(image_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Inspect the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Export the dataframe to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.to_csv(\"./data_out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# 5. Check out further notebooks or create your own!\n",
    "\n",
    "Congratulations! You have used `ammico` for an image analysis task. Check out [the documentation](https://github.com/ssciwr/AMMICO) for further tutorials on how to extract text from images or analyze video content! Do not hesitate to [get in touch](https://github.com/ssciwr/AMMICO/issues) with questions, feedback or any technical issues!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ammico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
