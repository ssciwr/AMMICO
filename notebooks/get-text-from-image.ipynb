{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcaa3da1",
   "metadata": {},
   "source": [
    "# Notebook for text extraction on image\n",
    "Inga Ulusoy, SSC, July 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running on google colab\n",
    "# flake8-noqa-cell\n",
    "import os\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # update python version\n",
    "    # install setuptools\n",
    "    !pip install setuptools==61 -qqq\n",
    "    # install misinformation\n",
    "    !pip install git+https://github.com/ssciwr/misinformation.git -qqq\n",
    "    # mount google drive for data and API key\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf362e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "import misinformation\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27675810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the models if they are not there yet\n",
    "!python -m spacy download en_core_web_md\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = misinformation.find_files(path=\"../data/all/\", limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf811ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in images[0:3]:\n",
    "    display(Image(filename=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = misinformation.utils.initialize_dict(images[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8b929f",
   "metadata": {},
   "source": [
    "# google cloud vision API\n",
    "First 1000 images per month are free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf74c0b-52fe-4fb8-b617-f18611e8f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\n",
    "    \"GOOGLE_APPLICATION_CREDENTIALS\"\n",
    "] = \"../data/misinformation-campaign-981aa55a3b13.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891b795-c7fe-454c-a45d-45fadf788142",
   "metadata": {},
   "source": [
    "## Inspect the elements per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ecc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "misinformation.explore_analysis(mydict, identify=\"text-on-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e72b5-0e57-4019-b45e-3e36a74e7f52",
   "metadata": {},
   "source": [
    "## Or directly analyze for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c78b1-7ff4-4213-86fa-6a0a2d05198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in mydict:\n",
    "    print(key)\n",
    "    mydict[key] = misinformation.text.TextDetector(\n",
    "        mydict[key], analyse_text=True\n",
    "    ).analyse_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c063eda",
   "metadata": {},
   "source": [
    "## Convert to dataframe and write csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdict = misinformation.utils.append_data_to_dict(mydict)\n",
    "df = misinformation.utils.dump_df(outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f05637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the csv\n",
    "df.to_csv(\"./data_out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc8ac0a",
   "metadata": {},
   "source": [
    "# Topic analysis\n",
    "The topic analysis is carried out using [BERTopic](https://maartengr.github.io/BERTopic/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4931941b",
   "metadata": {},
   "source": [
    "BERTopic takes a list of strings as input. The more items in the list, the better for the topic modeling.\n",
    "### Option 1: Use the dictionary as obtained from the above analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3450a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of all the text_english entries per analysed image from the mydict variable as above\n",
    "topic_df, most_frequent_topics = misinformation.text.PostprocessText(\n",
    "    mydict=mydict\n",
    ").analyse_topic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95667342",
   "metadata": {},
   "source": [
    "### Option 2: Read in a csv\n",
    "Not to analyse too many images on google Cloud Vision, use the csv output to obtain the text (when rerunning already analysed images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"data_out.csv\"\n",
    "topic_df, most_frequent_topics = misinformation.text.PostprocessText(\n",
    "    use_csv=True, csv_path=input_file_path\n",
    ").analyse_topic(return_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7704c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "print(topic_df)\n",
    "for topic in most_frequent_topics:\n",
    "    print(\"Topic:\", topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f32b4",
   "metadata": {},
   "source": [
    "## Compute the topics\n",
    "Now load the spacy pipeline and perform BERT topic modeling using an embedded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266dbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\n",
    "    \"en_core_web_md\",\n",
    "    exclude=[\"tagger\", \"parser\", \"ner\", \"attribute_ruler\", \"lemmatizer\"],\n",
    ")\n",
    "\n",
    "topic_model = BERTopic(embedding_model=nlp)\n",
    "# topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(list_text_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ef6d7",
   "metadata": {},
   "source": [
    "### Access frequent topics\n",
    "A topic of `-1` stands for an outlier and should be ignored. Topic count is the number of occurence of that topic. The output is structured from most frequent to least frequent topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3316770",
   "metadata": {},
   "source": [
    "### Get information for specific topic\n",
    "The most frequent topic can be accessed using the index \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca24a9",
   "metadata": {},
   "source": [
    "### Extract document level info\n",
    "Further information about the analysed texts can be extracted as a dataframe (and then exportet to csv if one wishes to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd9e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_document_info(list_text_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f701e",
   "metadata": {},
   "source": [
    "### Topic visualization\n",
    "The topics can also be visualized. Careful: This only works if there is sufficient data (quantity and quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac8349",
   "metadata": {},
   "source": [
    "### Visualize documents\n",
    "You can also visualize the documents for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2396a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "\n",
    "# Prepare embeddings\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(list_text_english, show_progress_bar=False)\n",
    "\n",
    "# Train BERTopic\n",
    "topic_model = BERTopic().fit(list_text_english, embeddings)\n",
    "\n",
    "# Run the visualization with the original embeddings\n",
    "topic_model.visualize_documents(list_text_english, embeddings=embeddings)\n",
    "\n",
    "# Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
    "reduced_embeddings = UMAP(\n",
    "    n_neighbors=10, n_components=2, min_dist=0.0, metric=\"cosine\"\n",
    ").fit_transform(embeddings)\n",
    "topic_model.visualize_documents(\n",
    "    list_text_english, reduced_embeddings=reduced_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eaf353",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "The model can be saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"misinfo_posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94edb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "da98320027a74839c7141b42ef24e2d47d628ba1f51115c13da5d8b45a372ec2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
